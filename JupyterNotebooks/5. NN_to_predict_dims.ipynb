{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "The idea is that we predict rotated linear dimension position from lines and text from the drawing.\n",
    "\n",
    "# Thoughts\n",
    "Basic logic is we split dataset to input lines or texts positions StartPoint, EndPoint, Position XYZ and predict dimension extension line poistion XLine1Point, XLine2Point XYZ.\n",
    "\n",
    "We going to group samples by FileId. That is each sample will contain variable length data (attributes of variable number of  lines and text) and variable output data (variable number of dimensions).\n",
    "\n",
    "I intend to [use RNN for it](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from processing import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassName</th>\n",
       "      <th>FileId</th>\n",
       "      <th>XLine1Point.X</th>\n",
       "      <th>XLine1Point.Y</th>\n",
       "      <th>XLine1Point.Z</th>\n",
       "      <th>XLine2Point.X</th>\n",
       "      <th>XLine2Point.Y</th>\n",
       "      <th>XLine2Point.Z</th>\n",
       "      <th>StartPoint.X</th>\n",
       "      <th>StartPoint.Y</th>\n",
       "      <th>StartPoint.Z</th>\n",
       "      <th>EndPoint.X</th>\n",
       "      <th>EndPoint.Y</th>\n",
       "      <th>EndPoint.Z</th>\n",
       "      <th>Position.X</th>\n",
       "      <th>Position.Y</th>\n",
       "      <th>Position.Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>006cb2dd-6f18-4203-8b70-fc865c08105a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.695776</td>\n",
       "      <td>35.642180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>006cb2dd-6f18-4203-8b70-fc865c08105a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.733352</td>\n",
       "      <td>10.433374</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>006cb2dd-6f18-4203-8b70-fc865c08105a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.733352</td>\n",
       "      <td>6.266707</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>006cb2dd-6f18-4203-8b70-fc865c08105a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.733352</td>\n",
       "      <td>22.584136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>006cb2dd-6f18-4203-8b70-fc865c08105a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.733352</td>\n",
       "      <td>18.417470</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89231</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>09bb1674-bff4-4ac7-a86d-60a9600ce899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.169657</td>\n",
       "      <td>92.228915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89232</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>09bb1674-bff4-4ac7-a86d-60a9600ce899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.2884</td>\n",
       "      <td>155.228915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>155.228915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89233</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>09bb1674-bff4-4ac7-a86d-60a9600ce899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2884</td>\n",
       "      <td>145.228915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.2884</td>\n",
       "      <td>145.228915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89234</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>09bb1674-bff4-4ac7-a86d-60a9600ce899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>316.663400</td>\n",
       "      <td>1.478915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89235</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>09bb1674-bff4-4ac7-a86d-60a9600ce899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>369.612047</td>\n",
       "      <td>1.688458</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89236 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ClassName                                FileId  XLine1Point.X  \\\n",
       "0      AcDbText  006cb2dd-6f18-4203-8b70-fc865c08105a            NaN   \n",
       "1      AcDbText  006cb2dd-6f18-4203-8b70-fc865c08105a            NaN   \n",
       "2      AcDbText  006cb2dd-6f18-4203-8b70-fc865c08105a            NaN   \n",
       "3      AcDbText  006cb2dd-6f18-4203-8b70-fc865c08105a            NaN   \n",
       "4      AcDbText  006cb2dd-6f18-4203-8b70-fc865c08105a            NaN   \n",
       "...         ...                                   ...            ...   \n",
       "89231  AcDbText  09bb1674-bff4-4ac7-a86d-60a9600ce899            NaN   \n",
       "89232  AcDbLine  09bb1674-bff4-4ac7-a86d-60a9600ce899            NaN   \n",
       "89233  AcDbLine  09bb1674-bff4-4ac7-a86d-60a9600ce899            NaN   \n",
       "89234  AcDbText  09bb1674-bff4-4ac7-a86d-60a9600ce899            NaN   \n",
       "89235  AcDbText  09bb1674-bff4-4ac7-a86d-60a9600ce899            NaN   \n",
       "\n",
       "       XLine1Point.Y  XLine1Point.Z  XLine2Point.X  XLine2Point.Y  \\\n",
       "0                NaN            NaN            NaN            NaN   \n",
       "1                NaN            NaN            NaN            NaN   \n",
       "2                NaN            NaN            NaN            NaN   \n",
       "3                NaN            NaN            NaN            NaN   \n",
       "4                NaN            NaN            NaN            NaN   \n",
       "...              ...            ...            ...            ...   \n",
       "89231            NaN            NaN            NaN            NaN   \n",
       "89232            NaN            NaN            NaN            NaN   \n",
       "89233            NaN            NaN            NaN            NaN   \n",
       "89234            NaN            NaN            NaN            NaN   \n",
       "89235            NaN            NaN            NaN            NaN   \n",
       "\n",
       "       XLine2Point.Z  StartPoint.X  StartPoint.Y  StartPoint.Z  EndPoint.X  \\\n",
       "0                NaN           NaN           NaN           NaN         NaN   \n",
       "1                NaN           NaN           NaN           NaN         NaN   \n",
       "2                NaN           NaN           NaN           NaN         NaN   \n",
       "3                NaN           NaN           NaN           NaN         NaN   \n",
       "4                NaN           NaN           NaN           NaN         NaN   \n",
       "...              ...           ...           ...           ...         ...   \n",
       "89231            NaN           NaN           NaN           NaN         NaN   \n",
       "89232            NaN       20.2884    155.228915           0.0      0.2884   \n",
       "89233            NaN        5.2884    145.228915           0.0     20.2884   \n",
       "89234            NaN           NaN           NaN           NaN         NaN   \n",
       "89235            NaN           NaN           NaN           NaN         NaN   \n",
       "\n",
       "       EndPoint.Y  EndPoint.Z  Position.X  Position.Y  Position.Z  \n",
       "0             NaN         NaN    7.695776   35.642180         0.0  \n",
       "1             NaN         NaN    8.733352   10.433374         0.0  \n",
       "2             NaN         NaN    8.733352    6.266707         0.0  \n",
       "3             NaN         NaN    8.733352   22.584136         0.0  \n",
       "4             NaN         NaN    8.733352   18.417470         0.0  \n",
       "...           ...         ...         ...         ...         ...  \n",
       "89231         NaN         NaN    4.169657   92.228915         0.0  \n",
       "89232  155.228915         0.0         NaN         NaN         NaN  \n",
       "89233  145.228915         0.0         NaN         NaN         NaN  \n",
       "89234         NaN         NaN  316.663400    1.478915         0.0  \n",
       "89235         NaN         NaN  369.612047    1.688458         0.0  \n",
       "\n",
       "[89236 rows x 17 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_pickle('test_dataset.pickle')\n",
    "# BUG: Dataset is filtered, we need all data from SOME files, not SOME data from All Files\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [\n",
    "    #'ClassName', \n",
    "    'StartPoint.X', 'StartPoint.Y', 'StartPoint.Z',\n",
    "    'EndPoint.X', 'EndPoint.Y', 'EndPoint.Z',\n",
    "    'Position.X', 'Position.Y', 'Position.Z']\n",
    "\n",
    "y_columns = [\n",
    "    #'ClassName', \n",
    "    'XLine1Point.X', 'XLine1Point.Y','XLine1Point.Z', \n",
    "    'XLine2Point.X', 'XLine2Point.Y', 'XLine2Point.Z']\n",
    "\n",
    "ent_features = len(x_columns)\n",
    "dim_features = len(y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityDataset(Dataset):\n",
    "    def __init__(self, pandasData):\n",
    "        self.data = pandasData\n",
    "        self.groupped = pandasData.groupby('FileId')\n",
    "        self.keys = list(self.groupped.groups.keys() )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # https://stackoverflow.com/questions/45147100/pandas-drop-columns-with-all-nans\n",
    "        \n",
    "        x = self.groupped.get_group(self.keys[index])[x_columns]\n",
    "        x = x.dropna( how ='all')\n",
    "        y = self.groupped.get_group(self.keys[index])[y_columns]\n",
    "        y = y.dropna(how = 'all')\n",
    "        #print(self.keys[index])\n",
    "        # if not y.empty:\n",
    "        #    print(x, y)\n",
    "        \n",
    "        return torch.tensor(np.array(x.values)), torch.tensor(np.array(y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = EntityDataset(test_data)\n",
    "for c,d in entities:\n",
    "    # print(c.shape, d.shape)\n",
    "    assert( c.shape[0] != 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "data_len = len(entities)\n",
    "\n",
    "validation_fraction = 0.2\n",
    "test_fraction       = 0.3\n",
    "\n",
    "val_split  = int(np.floor(validation_fraction * data_len))\n",
    "test_split = int(np.floor(test_fraction * data_len))\n",
    "indices = list(range(data_len))\n",
    "np.random.seed(228)\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_indices   = indices[:val_split]\n",
    "test_indices  = indices[val_split:test_split]\n",
    "train_indices = indices[test_split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler   = SubsetRandomSampler(val_indices)\n",
    "test_sampler  = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# https://stackoverflow.com/questions/64586575/adding-class-objects-to-pytorch-dataloader-batch-must-contain-tensors\n",
    "def custom_collate(sample):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for (xx, yy) in sample:\n",
    "        #if torch.count_nonzero(xx) > 0:\n",
    "            # print(xx)\n",
    "        x.append(xx)\n",
    "        #if torch.count_nonzero(yy) > 0:\n",
    "        y.append(yy)\n",
    "    #print(len(x), len(y))\n",
    "    return x, y\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(entities, batch_size = batch_size, sampler = train_sampler, collate_fn=custom_collate)\n",
    "val_loader   = torch.utils.data.DataLoader(entities, batch_size = batch_size, sampler = val_sampler, collate_fn=custom_collate)\n",
    "test_loader  = torch.utils.data.DataLoader(entities, batch_size = batch_size, sampler = test_sampler, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "torch.Size([990, 9])\n",
      "torch.Size([922, 9])\n",
      "torch.Size([1, 6])\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "(a,b) = next(iter(train_loader))\n",
    "print(len(a),len(b))\n",
    "for (x,y) in iter(train_loader):\n",
    "    for xx in x:\n",
    "        print(xx.shape)\n",
    "        pass\n",
    "    for yy in y:\n",
    "        print(yy.shape)\n",
    "    # print(a.shape,b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnEncoder(nn.Module):\n",
    "    def __init__(self, ent_features, learned_size, n_neurons = 16):\n",
    "        super(RnnEncoder, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size = ent_features, hidden_size = learned_size)\n",
    "        self.learned_size = learned_size\n",
    "        self.ent_features = ent_features\n",
    "        \n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(learned_size, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def init_hidden(self,batch_size):\n",
    "        self.hidden = torch.zeros(1, batch_size, self.learned_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input of shape (seq_len, batch, input_size)\n",
    "        batch_size = len(x)\n",
    "        \n",
    "        hiddens = torch.zeros([batch_size, self.learned_size], dtype = torch.float32, device = device)\n",
    "        outs = torch.zeros([batch_size, 1], dtype = torch.int32, device = device)\n",
    "        for j in range(batch_size):\n",
    "            f = x[j]\n",
    "            entities_count = f.shape[0]\n",
    "            self.init_hidden(entities_count)\n",
    "            inp = torch.zeros([entities_count, 1, self.ent_features], dtype = torch.float32, device = device)\n",
    "            # print(inp.shape, f.shape)\n",
    "            inp[:,0,:] = f[:,:]\n",
    "            \n",
    "            outp, h_n = self.rnn(inp)\n",
    "            # print('h_N', h_n.shape)\n",
    "            # print('cell out', outp.shape)\n",
    "            n = self.fcn(outp)\n",
    "            \n",
    "            # https://stackoverflow.com/questions/48005152/extract-the-count-of-positive-and-negative-values-from-an-array\n",
    "            cou = np.sum(np.array(n.detach().numpy()) > 0, axis = 0)\n",
    "            # print(cou)\n",
    "            outs[j] = torch.tensor(cou) \n",
    "            hiddens[j] = h_n\n",
    "            j = j + 1\n",
    "                \n",
    "        return outs, hiddens\n",
    "            \n",
    "class RnnDecoder(nn.Module):\n",
    "    def __init__(self, learned_size, dim_features):\n",
    "        super(RnnDecoder, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size = learned_size, hidden_size = dim_features)\n",
    "        self.learned_size = learned_size\n",
    "        self.dim_features = dim_features\n",
    "        \n",
    "    def forward(self, x, out_counts):\n",
    "        '''Receives tensor with hidden state and number of dimensions tensor per each file.\n",
    "            Returns a list of tensors with dimension parameters'''\n",
    "        # input of shape (seq_len, batch, input_size)\n",
    "        \n",
    "        result = []\n",
    "        for j in range(batch_size):\n",
    "            dim_count = out_counts[j]\n",
    "            outs = torch.zeros([dim_count,dim_features])\n",
    "            if dim_count > 0:\n",
    "                inp = torch.zeros([dim_count, 1, self.learned_size], dtype=torch.float32, device = device)\n",
    "                xj = x[j]\n",
    "                # print(inp.shape, xj.shape)\n",
    "                inp[:,0] = xj\n",
    "                outs, hiddens = self.rnn(inp)\n",
    "                print(\"decoder outs.shape\", outs.shape)\n",
    "                # we remove batch dimension, as batches here are list\n",
    "                # https://pytorch.org/docs/stable/generated/torch.squeeze.html\n",
    "                outs = outs.squeeze(dim = 1)\n",
    "            result.append(outs)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs x: 2 x torch.Size([29404, 9]) y: 2 x torch.Size([367, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned shape: torch.Size([2, 1024])\n",
      "outs shape: torch.Size([2, 1]) outs_value tensor([[42],\n",
      "        [ 0]], dtype=torch.int32)\n",
      "decoder outs.shape torch.Size([42, 1, 6])\n",
      "decoded: 2 x torch.Size([42, 6])\n"
     ]
    }
   ],
   "source": [
    "rnn_encoder = RnnEncoder(ent_features, 1024).to(device)\n",
    "rnn_decoder = RnnDecoder(1024, dim_features).to(device)\n",
    "(x,y) = next(iter(train_loader))\n",
    "print('inputs','x:',len(x),'x',x[0].shape,'y:',len(y),'x',y[0].shape)\n",
    "outs_numbers, learned = rnn_encoder(x)\n",
    "print('learned shape:', learned.shape)\n",
    "print(\"outs shape:\", outs.shape, 'outs_value', outs)\n",
    "# make sure something is passed\n",
    "outs[0] = 42\n",
    "decoded = rnn_decoder(learned, outs)\n",
    "print('decoded:',len(decoded),'x', decoded[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([603, 9])\n",
      "torch.Size([955, 9])\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zeros(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-424-c5ddf1a5773e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts_numbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-424-c5ddf1a5773e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mouts_numbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts_numbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# print(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-409-a81b20164c14>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, out_counts)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mdim_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdim_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearned_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zeros(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 1"
     ]
    }
   ],
   "source": [
    "# test run all data samples\n",
    "for (x,y) in iter(train_loader):\n",
    "    try:\n",
    "        outs_numbers, learned = rnn_encoder(x)\n",
    "        results = rnn_decoder(outs_numbers, learned)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        for xx in x:\n",
    "            print(xx.shape)\n",
    "        print(outs_numbers.shape)\n",
    "        raise(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as LA\n",
    "# https://stackoverflow.com/questions/47060685/chamfer-distance-between-two-point-clouds-in-tensorflow\n",
    "def array2samples_distance(array1, array2):\n",
    "    \"\"\"\n",
    "    arguments: \n",
    "        array1: the array, size: (num_point, num_feature)\n",
    "        array2: the samples, size: (num_point, num_feature)\n",
    "    returns:\n",
    "        distances: each entry is the distance from a sample to array1 \n",
    "    \"\"\"\n",
    "    num_point, num_features = array1.shape\n",
    "    expanded_array1 = np.tile(array1, (num_point, 1))\n",
    "    expanded_array2 = np.reshape(\n",
    "            np.tile(np.expand_dims(array2, 1), \n",
    "                    (1, num_point, 1)),\n",
    "            (-1, num_features))\n",
    "    distances = LA.norm(expanded_array1-expanded_array2, axis=1)\n",
    "    distances = np.reshape(distances, (num_point, num_point))\n",
    "    distances = np.min(distances, axis=1)\n",
    "    distances = np.mean(distances)\n",
    "    return distances\n",
    "\n",
    "def chamfer_distance_numpy(array1, array2):\n",
    "    batch_size, num_point, num_features = array1.shape\n",
    "    dist = 0\n",
    "    for i in range(batch_size):\n",
    "        av_dist1 = array2samples_distance(array1[i], array2[i])\n",
    "        av_dist2 = array2samples_distance(array2[i], array1[i])\n",
    "        dist = dist + (av_dist1+av_dist2)/batch_size\n",
    "    return dist\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "def chamfer_distance_sklearn(array1,array2):\n",
    "    batch_size, num_point = array1.shape[:2]\n",
    "    dist = 0\n",
    "    for i in range(batch_size):\n",
    "        tree1 = KDTree(array1[i], leaf_size=num_point+1)\n",
    "        tree2 = KDTree(array2[i], leaf_size=num_point+1)\n",
    "        distances1, _ = tree1.query(array2[i])\n",
    "        distances2, _ = tree2.query(array1[i])\n",
    "        av_dist1 = np.mean(distances1)\n",
    "        av_dist2 = np.mean(distances2)\n",
    "        dist = dist + (av_dist1+av_dist2)/batch_size\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.7649], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def my_chamfer_distance(out, y):\n",
    "    loss = torch.zeros(1, dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        # we need extra dimension for batch\n",
    "        xxx = torch.unsqueeze(out[i], dim = 0)\n",
    "        yyy = torch.unsqueeze(y[i],dim = 0)    \n",
    "        # print(yyy.shape)\n",
    "        # print(xxx.shape)    \n",
    "\n",
    "        if xxx.shape[1] == 0 and yyy.shape[1] == 0:\n",
    "            # loss += 0\n",
    "            continue\n",
    "        if xxx.shape[1] == 0:\n",
    "            loss = loss + math.inf\n",
    "            continue\n",
    "        if yyy.shape[1] == 0:\n",
    "            loss = loss + math.inf\n",
    "            continue\n",
    "        # https://discuss.pytorch.org/t/leaf-variable-was-used-in-an-inplace-operation/308\n",
    "        curr_loss = chamfer_distance_sklearn(xxx.detach().numpy(), yyy.detach().numpy()).sum()\n",
    "        loss = loss + curr_loss\n",
    "    return loss\n",
    "\n",
    "# print(my_chamfer_distance(decoded, y))\n",
    "a = [torch.randn([3,6]), torch.randn([2,6])]\n",
    "b = [torch.randn([4,6]), torch.randn([1,6])]\n",
    "# print(a,b)\n",
    "print(my_chamfer_distance(a,b))\n",
    "\n",
    "class ChamferDistance(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return my_chamfer_distance(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(loss_history, train_history, val_history):\n",
    "    plt.ylabel('Accuracy @ epoch')\n",
    "    \n",
    "    train, = plt.plot(train_history)\n",
    "    train.set_label(\"train\")\n",
    "    validation, = plt.plot(val_history)\n",
    "    validation.set_label(\"validation\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(encoder, decoder, train_loader, val_loader, loss, decoder_opt,encoder_opt, epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    loss_history = []\n",
    "    train_istory = []\n",
    "    val_history  = []\n",
    "    train_accuracy = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        loss_accumulated = 0\n",
    "        \n",
    "        i_step = 1\n",
    "        for _, (x,y) in enumerate(train_loader):\n",
    "            \n",
    "            decoder_opt.zero_grad()\n",
    "            encoder_opt.zero_grad()\n",
    "            \n",
    "            outs_num, learned = encoder(x)\n",
    "            \n",
    "            decoded = decoder(learned, outs_num)\n",
    "            loss_value = loss(decoded, y)\n",
    "            \n",
    "            loss_value.backward()\n",
    "            decoder_opt.step()\n",
    "            encoder_opt.step()\n",
    "            \n",
    "            loss_accumulated += loss_value\n",
    "            \n",
    "            #val_accuracy = compute_accuracy(model, val_loader)\n",
    "            print('[{0} @ {4:.1f} sec] Loss: {1:4f} Train err: {2:2.2f}% Val err: {3:2.2f}%'. format(\n",
    "                epoch,\n",
    "                loss_value.item(),\n",
    "                (1 - train_accuracy) * 100,\n",
    "                (1 - val_accuracy) * 100,\n",
    "                time.time() - start\n",
    "            ))\n",
    "        \n",
    "        # loss_history.append(float(loss_accum / i_step))\n",
    "        # val_history.append(val_accuracy)\n",
    "        # clear_output(wait=True)\n",
    "        \n",
    "        i_step += 1\n",
    "        \n",
    "    plot_history(loss_history, train_history, val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 @ 0.8 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 3.7 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 4.3 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 5.0 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 5.8 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 16.7 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 19.2 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 20.5 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 21.1 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n",
      "[0 @ 22.7 sec] Loss:  inf Train err: 100.00% Val err: 100.00%\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-416-0f0ea39dede0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdecoder_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mencoder_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     epochs = epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-415-805c1fdd605e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(encoder, decoder, train_loader, val_loader, loss, decoder_opt, encoder_opt, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mouts_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-409-a81b20164c14>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, out_counts)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mdim_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdim_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 3\n",
    "decoder_optimizer = torch.optim.Adam(rnn_decoder.parameters(), lr = lr)\n",
    "encoder_optimizer = torch.optim.Adam(rnn_encoder.parameters(), lr=lr)\n",
    "loss = ChamferDistance()\n",
    "\n",
    "train_model(\n",
    "    encoder = rnn_encoder, \n",
    "    decoder = rnn_decoder, \n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    loss = loss,\n",
    "    decoder_opt = decoder_optimizer,\n",
    "    encoder_opt = encoder_optimizer,\n",
    "    epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.eval()\n",
    "for (x,y) in test_loader:\n",
    "    with torch.no_grad():\n",
    "        output = model.forward(x.to(device))\n",
    "        accuracy = compute_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
