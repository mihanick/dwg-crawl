{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "The idea is that we predict rotated linear dimension position from lines and text from the drawing.\n",
    "\n",
    "# Thoughts\n",
    "Basic logic is we split dataset to input lines or texts positions StartPoint, EndPoint, Position XYZ and predict dimension extension line poistion XLine1Point, XLine2Point XYZ.\n",
    "\n",
    "We going to group samples by FileId. That is each sample will contain variable length data (attributes of variable number of  lines and text) and variable output data (variable number of dimensions).\n",
    "\n",
    "I intend to [use RNN for it](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DwgDataset\n",
    "batch_size = 1\n",
    "\n",
    "dwg_dataset = DwgDataset(pickle_file = 'test_dataset.pickle', batch_size = batch_size)\n",
    "\n",
    "train_loader = dwg_dataset.train_loader\n",
    "val_loader   = dwg_dataset.val_loader\n",
    "test_loader  = dwg_dataset.test_loader\n",
    "\n",
    "ent_features = dwg_dataset.entities.ent_features\n",
    "dim_features = dwg_dataset.entities.dim_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,d in dwg_dataset.entities:\n",
    "    # print(c.shape, d.shape)\n",
    "    # make sure we have every training sample not empty\n",
    "    assert( c.shape[0] != 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "torch.Size([1617, 9])\n",
      "torch.Size([0, 6])\n"
     ]
    }
   ],
   "source": [
    "(a,b) = next(iter(train_loader))\n",
    "print(len(a),len(b))\n",
    "for (x,y) in iter(train_loader):\n",
    "    for xx in x:\n",
    "        print(xx.shape)\n",
    "        pass\n",
    "    for yy in y:\n",
    "        print(yy.shape)\n",
    "    # print(a.shape,b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import RnnDecoder, RnnEncoder\n",
    "rnn_encoder = RnnEncoder(ent_features, 1024, enforced_device = device).to(device)\n",
    "rnn_decoder = RnnDecoder(1024, dim_features, enforced_device = device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs x: 1 x torch.Size([172, 9]) y: 1 x torch.Size([55, 6])\n",
      "learned shape: torch.Size([1, 1024])\n",
      "outs shape: torch.Size([1, 1]) outs_value tensor([[0.]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "decoded: 1 x torch.Size([42, 6])\n"
     ]
    }
   ],
   "source": [
    "(x,y) = next(iter(train_loader))\n",
    "print('inputs','x:',len(x),'x',x[0].shape,'y:',len(y),'x',y[0].shape)\n",
    "outs_numbers, learned = rnn_encoder(x)\n",
    "print('learned shape:', learned.shape)\n",
    "print(\"outs shape:\", outs_numbers.shape, 'outs_value', outs_numbers)\n",
    "# make sure something is passed\n",
    "outs_numbers[0] = 42\n",
    "decoded = rnn_decoder(outs_numbers, learned)\n",
    "print('decoded:',len(decoded),'x', decoded[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from train import train_model, plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0-0 @ 0.4 sec] Log10 Loss: 2.790644 Train err: 89.2%\n",
      "[0-1 @ 0.5 sec] Log10 Loss: 1.313294 Train err: 100.0%\n",
      "[0-2 @ 0.7 sec] Log10 Loss: 2.187478 Train err: 94.9%\n",
      "[0-3 @ 0.8 sec] Log10 Loss: 3.240792 Train err: 85.0%\n",
      "[0-4 @ 0.8 sec] Log10 Loss: 1.621026 Train err: 100.0%\n",
      "[0-5 @ 0.9 sec] Log10 Loss: 1.323988 Train err: 100.0%\n",
      "[0-6 @ 0.9 sec] Log10 Loss: 1.614212 Train err: 97.7%\n",
      "[0-7 @ 1.0 sec] Log10 Loss: 1.463251 Train err: 100.0%\n",
      "[0-8 @ 1.0 sec] Log10 Loss: 2.319319 Train err: 82.0%\n",
      "[0-9 @ 1.1 sec] Log10 Loss: 1.155379 Train err: 0.0%\n",
      "[0-10 @ 1.2 sec] Log10 Loss: 1.476206 Train err: 100.0%\n",
      "[0-11 @ 3.2 sec] Log10 Loss: 3.400877 Train err: 90.3%\n",
      "[0-12 @ 3.2 sec] Log10 Loss: 2.665187 Train err: 92.6%\n",
      "[0-13 @ 3.3 sec] Log10 Loss: 1.785856 Train err: 95.6%\n",
      "[0-14 @ 3.5 sec] Log10 Loss: 1.514662 Train err: 100.0%\n",
      "[0-15 @ 3.6 sec] Log10 Loss: 1.820800 Train err: 91.5%\n",
      "[0-16 @ 3.6 sec] Log10 Loss: 1.435421 Train err: 100.0%\n",
      "[0-17 @ 4.0 sec] Log10 Loss: 1.842803 Train err: 85.6%\n",
      "[0-18 @ 4.2 sec] Log10 Loss: 1.192253 Train err: 100.0%\n",
      "[0-19 @ 4.3 sec] Log10 Loss: 1.222563 Train err: 100.0%\n",
      "[0-20 @ 4.3 sec] Log10 Loss: 1.309221 Train err: 100.0%\n",
      "Epoch [0] validation error: 57.072%\n",
      "[1-0 @ 5.0 sec] Log10 Loss: 1.514662 Train err: 100.0%\n",
      "[1-1 @ 5.2 sec] Log10 Loss: 1.192253 Train err: 100.0%\n",
      "[1-2 @ 5.2 sec] Log10 Loss: 1.155379 Train err: 0.0%\n",
      "[1-3 @ 5.4 sec] Log10 Loss: 1.476206 Train err: 100.0%\n",
      "[1-4 @ 5.8 sec] Log10 Loss: 2.790644 Train err: 89.2%\n",
      "[1-5 @ 5.8 sec] Log10 Loss: 1.463251 Train err: 100.0%\n",
      "[1-6 @ 5.8 sec] Log10 Loss: 1.785856 Train err: 95.6%\n",
      "[1-7 @ 6.1 sec] Log10 Loss: 2.187478 Train err: 94.9%\n",
      "[1-8 @ 6.5 sec] Log10 Loss: 1.842803 Train err: 85.6%\n",
      "[1-9 @ 6.6 sec] Log10 Loss: 1.621026 Train err: 100.0%\n",
      "[1-10 @ 6.6 sec] Log10 Loss: 1.435421 Train err: 100.0%\n",
      "[1-11 @ 8.5 sec] Log10 Loss: 3.400877 Train err: 90.3%\n",
      "[1-12 @ 8.6 sec] Log10 Loss: 1.313294 Train err: 100.0%\n",
      "[1-13 @ 8.7 sec] Log10 Loss: 2.319319 Train err: 82.0%\n",
      "[1-14 @ 8.7 sec] Log10 Loss: 1.820800 Train err: 91.5%\n",
      "[1-15 @ 8.8 sec] Log10 Loss: 1.614212 Train err: 97.7%\n",
      "[1-16 @ 8.9 sec] Log10 Loss: 3.240792 Train err: 85.0%\n",
      "[1-17 @ 8.9 sec] Log10 Loss: 1.323988 Train err: 100.0%\n",
      "[1-18 @ 9.0 sec] Log10 Loss: 1.309221 Train err: 100.0%\n",
      "[1-19 @ 9.0 sec] Log10 Loss: 1.222563 Train err: 100.0%\n",
      "[1-20 @ 9.1 sec] Log10 Loss: 2.665187 Train err: 92.6%\n",
      "Epoch [1] validation error: 57.072%\n",
      "[2-0 @ 9.6 sec] Log10 Loss: 1.309221 Train err: 100.0%\n",
      "[2-1 @ 9.6 sec] Log10 Loss: 1.155379 Train err: 0.0%\n",
      "[2-2 @ 9.7 sec] Log10 Loss: 3.240792 Train err: 85.0%\n",
      "[2-3 @ 10.2 sec] Log10 Loss: 1.842803 Train err: 85.6%\n",
      "[2-4 @ 10.3 sec] Log10 Loss: 2.665187 Train err: 92.6%\n",
      "[2-5 @ 10.3 sec] Log10 Loss: 1.614212 Train err: 97.7%\n",
      "[2-6 @ 10.3 sec] Log10 Loss: 1.222563 Train err: 100.0%\n",
      "[2-7 @ 10.4 sec] Log10 Loss: 1.463251 Train err: 100.0%\n",
      "[2-8 @ 10.6 sec] Log10 Loss: 2.187478 Train err: 94.9%\n",
      "[2-9 @ 10.7 sec] Log10 Loss: 1.785856 Train err: 95.6%\n",
      "[2-10 @ 10.7 sec] Log10 Loss: 1.435421 Train err: 100.0%\n",
      "[2-11 @ 10.7 sec] Log10 Loss: 1.323988 Train err: 100.0%\n",
      "[2-12 @ 10.7 sec] Log10 Loss: 1.621026 Train err: 100.0%\n",
      "[2-13 @ 10.8 sec] Log10 Loss: 1.820800 Train err: 91.5%\n",
      "[2-14 @ 11.2 sec] Log10 Loss: 2.790644 Train err: 89.2%\n",
      "[2-15 @ 11.2 sec] Log10 Loss: 2.319319 Train err: 82.0%\n",
      "[2-16 @ 11.4 sec] Log10 Loss: 1.476206 Train err: 100.0%\n",
      "[2-17 @ 11.6 sec] Log10 Loss: 1.514662 Train err: 100.0%\n",
      "[2-18 @ 11.8 sec] Log10 Loss: 1.192253 Train err: 100.0%\n",
      "[2-19 @ 11.9 sec] Log10 Loss: 1.313294 Train err: 100.0%\n",
      "[2-20 @ 13.8 sec] Log10 Loss: 3.400877 Train err: 90.3%\n",
      "Epoch [2] validation error: 57.072%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5wV9X3/8dd7L7JcFQEVQQKkJiqIQFa0MUGsNoJpJEYSoTEJxkhj4iVp609bWzXaNl76MCaPGC2xaEyNSFAjSbw0FyxaxYAWEfGGqGFF5WK8Agq7n98fM7sclnN2z+LOOeye9/PxOI8zl+/MfHY4fD8z35n5jiICMzOrXFXlDsDMzMrLicDMrMI5EZiZVTgnAjOzCudEYGZW4WrKHUBHDRw4MIYPH17uMMzMupRHH310Q0QMyjevyyWC4cOHs3Tp0nKHYWbWpUh6qdA8Nw2ZmVU4JwIzswrnRGBmVuGcCMzMKlxmiUDSHEnrJK1oo8wkScskPSnpf7KKxczMCsvyjOAmYHKhmZL2An4EnBgRo4DPZxiLmZkVkFkiiIhFwOttFPlr4I6I+GNafl1WsZiZWWHlfI7gI0CtpPuBvsD3I+LmfAUlzQJmAQwbNmyXNnbFH67g6def3rVIzcx2AwftfRDnTzi/09dbzovFNcDHgE8DxwP/LOkj+QpGxOyIqI+I+kGD8j4YZ2Zmu6icZwQNwIaIeBd4V9Ii4DDg2Sw2lkUWNTPrDsp5RnAX8ElJNZJ6AUcAT5UxHjOzipTZGYGkW4FJwEBJDcDFQC1ARFwfEU9JuhdYDjQBN0REwVtNzcwsG5klgoiYUUSZq4CrsorBzMza5yeLzcwqnBOBmVmFcyIwM6twTgRmZhXOicDMrMI5EZiZVTgnAjOzCudEYGZW4ZwIzMwqnBOBmVmFcyIwM6twTgRmZhXOicDMrMI5EZiZVTgnAjOzCpdZIpA0R9I6SW2+bEbS4ZIaJU3LKhYzMyssyzOCm4DJbRWQVA1cAdyXYRxmZtaGzBJBRCwCXm+n2NnA7cC6rOIwM7O2le0agaQhwEnA9eWKwczMynux+Brg/IhobK+gpFmSlkpaun79+hKEZmZWOTJ7eX0R6oG5kgAGAidI2hYRv2hdMCJmA7MB6uvro6RRmpl1c2VLBBExonlY0k3Ar/IlATMzy1ZmiUDSrcAkYKCkBuBioBYgInxdwMxsN5FZIoiIGR0oOzOrOMzMrG1+stjMrMI5EZiZVTgnAjOzCudEYGZW4ZwIzMwqnBOBmVmFcyIwM6twTgRmZhXOicDMrMI5EZiZVTgnAjOzCudEYGZW4ZwIzMwqnBOBmVmFcyIwM6twTgRmZhUus0QgaY6kdZJWFJj/RUnL089Dkg7LKhYzMyssyzOCm4DJbcx/ATg6IsYAl5G+nN7MzEory1dVLpI0vI35D+WMLgaGZhWLmZkVtrtcIzgduKfcQZiZVaLMzgiKJekYkkTwiTbKzAJmAQwbNqxEkZmZVYaynhFIGgPcAEyNiI2FykXE7Iioj4j6QYMGlS5AM7MKULZEIGkYcAfwpYh4tlxxmJlVusyahiTdCkwCBkpqAC4GagEi4nrgImAA8CNJANsioj6reMzMLL8s7xqa0c78rwFfy2r7ZmZWnN3lriEzMyuTds8IJPUATgaG55aPiEuzC8vMzEqlmKahu4A3gUeB97INx8zMSq2YRDA0ItrqKsLMzLqwYq4RPCTp0MwjMTOzsih4RiDpCSDSMqdJWk3SNCQg0s7izMysi2uraeivShaFmZmVTcGmoYh4KSJeAgYDr+eMvw7sV6oAzcwsW8VcI7gOeCdn/N10mpmZdQPFJAJFRDSPREQTu0GvpWZm1jmKSQSrJZ0jqTb9nAuszjowMzMrjWISwdeBjwMvp58jSN8NYGZmXV+7TTwRsQ6YXoJYzMysDNo9I5A0VNKdktZJek3S7ZL8fmEzs26imKahG4EFwP7AEOCX6TQzM+sGikkEgyLixojYln5uAvy+SDOzbqKYRLBB0qmSqtPPqUDB9ws3kzQnbU5aUWC+JP1A0ipJyyWN72jwZmb2wRWTCL4KfAF4Nf1MS6e15yagrV5LpwAHpp9Z+CE1M7OyKOauoT8CJ3Z0xRGxSNLwNopMBW5OH1ZbLGkvSYMj4pWObsvMzHZdMXcNjZT0S0nr06aeuySN7IRtDwHW5Iw3pNPyxTBL0lJJS9evX98JmzYzs2bFNA39DJhH0vnc/sDPgVs7YdvKMy3yTCMiZkdEfUTUDxrk69RmZp2pmD6DFBE/zRn/L0lndcK2G4ADcsaHAms7Yb1m1oVs3bqVhoYGtmzZUu5QuoW6ujqGDh1KbW1t0csUkwgWSroAmEtyxH4K8GtJewNExOu7EizJswlnSZpL0m3Fm74+YFZ5Ghoa6Nu3L8OHD0fK11BgxYoINm7cSENDAyNGjCh6uWISwSnp99+0mv5VksSQ93qBpFuBScBASQ3AxUBtGuz1wN3ACcAqYBNwWtFRm1m3sWXLFieBTiKJAQMG0NFrqcXcNVR8WtlxuRntzA/gm7uybjPrXpwEOs+u7Mti7hrqJemfJM1Oxw+U5NdYmpl1E8X2NfQ+SVfUkFzk/ZfMIjIzK6E33niDH/3oRx1e7oQTTuCNN97IIKLSKyYRfDgirgS2AkTEZvLf+mlm1uUUSgSNjY1tLnf33Xez1157ZRVWSRVzsfh9ST1J7/GX9GHgvUyjMjMrkQsuuIDnn3+esWPHUltbS58+fRg8eDDLli1j5cqVfPazn2XNmjVs2bKFc889l1mzkvdyDR8+nKVLl/LOO+8wZcoUPvGJT/DQQw8xZMgQ7rrrLnr27Fnmv6x4xSSCi4F7gQMk3QIcBczMMigzq0zf+eWTrFz7Vqeu85D9+3HxZ0YVnH/55ZezYsUKli1bxv3338+nP/1pVqxY0XL75Zw5c9h7773ZvHkzhx9+OCeffDIDBgzYYR3PPfcct956Kz/+8Y/5whe+wO23386pp57aqX9Hloq5a+g3kh4DjiRpEjo3IjZkHpmZWRlMmDBhh3vwf/CDH3DnnXcCsGbNGp577rmdEsGIESMYO3YsAB/72Md48cUXSxZvZyjmjICI2Aj8OuNYzKzCtXXkXiq9e/duGb7//vv57W9/y8MPP0yvXr2YNGlS3iege/To0TJcXV3N5s2bSxJrZynmYrGZWbfVt29f3n777bzz3nzzTfr370+vXr14+umnWbx4cYmjK42izgjMzLqrAQMGcNRRRzF69Gh69uzJvvvu2zJv8uTJXH/99YwZM4aPfvSjHHnkkWWMNDtKHvBtp1DSr9AIYF1ErGmvfJbq6+tj6dKl5QzBzDrRU089xcEHH1zuMLqVfPtU0qMRUZ+vfJtnBJJGAFcDjSR9Au0jaRDw1YjwiwHMzLqBgolA0lDgNuDUiHg2Z/po4EpJPweWOCGYmXVtbV0svgi4ICKelTRf0puSHgYeBKpJ3l98USmCNDOz7LSVCMZHxO/T4QAOjYg/B8YAdRHxGJC3vcnMzLqOthJBraTmpqORwJ/S4TfY/g6CHjstZWZmXUpbF4sXAlOB20m6mfidpOdJksClko4FHsk+RDMzy1JbZwT/BlwoaVRE/Iqki4lzgT8H1gBXAJe1tXJJkyU9I2lV+rrL1vOHSVoo6f8kLZd0wq7/KWZm2evTpw8Aa9euZdq0aXnLTJo0ifZuc7/mmmvYtGlTy3g5u7UueEYQEeskfR74kaR1wGKS20g/DnyI5G6igi+bl1QNXAv8Jck7DJZIWhARK3OK/RMwLyKuk3QIyesrh3/Av8nMLHP7778/8+fP3+Xlr7nmGk499VR69eoFJN1al0ubXUxExPMRcTxwKfAasBH4t4g4OiKebmfdE4BVEbE6It4H5pI0Ne2wCaBfOrwnUDCxmJll4fzzz9/hfQSXXHIJ3/nOdzj22GMZP348hx56KHfddddOy7344ouMHj0agM2bNzN9+nTGjBnDKaecskNfQ2eeeSb19fWMGjWKiy++GEg6slu7di3HHHMMxxxzDJB0a71hQ9Kf59VXX83o0aMZPXo011xzTcv2Dj74YM444wxGjRrFpz71qU7r06jYTueeA57r4LqHkDQhNWsAjmhV5hLgvyWdDfQGjsu3IkmzgFkAw4YN62AYZtZl3HMBvPpE565zv0NhyuUFZ0+fPp1vfetbfOMb3wBg3rx53HvvvXz729+mX79+bNiwgSOPPJITTzyx4PuAr7vuOnr16sXy5ctZvnw548ePb5n3r//6r+y99940NjZy7LHHsnz5cs455xyuvvpqFi5cyMCBA3dY16OPPsqNN97II488QkRwxBFHcPTRR9O/f//MurvOstO5fHusdX8WM4CbImIocALwU0k7xRQRsyOiPiLqBw0alEGoZlapxo0bx7p161i7di2PP/44/fv3Z/DgwfzjP/4jY8aM4bjjjuPll1/mtddeK7iORYsWtVTIY8aMYcyYMS3z5s2bx/jx4xk3bhxPPvkkK1euLLQaAB588EFOOukkevfuTZ8+ffjc5z7HAw88AGTX3XWWnc41AAfkjA9l56af04HJABHxsKQ6YCCwLsO4zGx31caRe5amTZvG/PnzefXVV5k+fTq33HIL69ev59FHH6W2tpbhw4fn7X46V76zhRdeeIF///d/Z8mSJfTv35+ZM2e2u562+n/Lqrvrds8IJJ0lqf8urHsJcKCkEZL2AKYDC1qV+SNwbLqdg4E6wF1WmFlJTZ8+nblz5zJ//nymTZvGm2++yT777ENtbS0LFy7kpZdeanP5iRMncssttwCwYsUKli9fDsBbb71F79692XPPPXnttde45557WpYp1P31xIkT+cUvfsGmTZt49913ufPOO/nkJz/ZiX/tzoo5I9iP5I6fx4A5wH1RRJelEbFN0lnAfSRdUsyJiCclXQosjYgFwN8BP5b0bZJmo5nFrNvMrDONGjWKt99+myFDhjB48GC++MUv8pnPfIb6+nrGjh3LQQcd1ObyZ555Jqeddhpjxoxh7NixTJgwAYDDDjuMcePGMWrUKEaOHMlRRx3VssysWbOYMmUKgwcPZuHChS3Tx48fz8yZM1vW8bWvfY1x48Zl+tazYruhFvAp4DSSbiXmAf8ZEc9nFlkB7obarHtxN9Sdr6PdUBd1sTg9Sn81/WwD+gPzJV35wcI1M7Nya7dpSNI5wFeADcANwHkRsTW9u+c54P9lG6KZmWWpmGsEA4HPRcQOV0sioknSX2UTlpmZlUoxTUN3A683j0jqK+kIgIh4KqvAzMysNIpJBNcB7+SMv5tOMzOzbqCYRKDcWzojoolsH0QzM7MSKiYRrJZ0jqTa9HMusDrrwMzMSqW5a+lKVUwi+DpJ19Mvs73juFlZBmVmZqXTbiKIiHURMT0i9omIfSPiryPCfQGZWbcTEZx33nmMHj2aQw89lNtuuw2AV155hYkTJzJ27FhGjx7NAw88QGNjIzNnzmwp+73vfa/M0e+6Yp4jqCPpHG4USV9AAETEVzOMy8wq0BV/uIKnX2/vVScdc9DeB3H+hPOLKnvHHXewbNkyHn/8cTZs2MDhhx/OxIkT+dnPfsbxxx/PhRdeSGNjI5s2bWLZsmW8/PLLrFixAqBsbxfrDMU0Df2UpL+h44H/IelFdOeekszMurgHH3yQGTNmUF1dzb777svRRx/NkiVLOPzww7nxxhu55JJLeOKJJ+jbty8jR45k9erVnH322dx7773069ev/Q3spoq5++fPIuLzkqZGxE8k/YykIzkzs05V7JF7Vgr1vTZx4kQWLVrEr3/9a770pS9x3nnn8eUvf5nHH3+c++67j2uvvZZ58+YxZ86cEkfcOYo5I9iafr8haTTJKyWHZxaRmVmZTJw4kdtuu43GxkbWr1/PokWLmDBhAi+99BL77LMPZ5xxBqeffjqPPfYYGzZsoKmpiZNPPpnLLruMxx57rNzh77Jizghmp+8j+CeS9wn0Af4506jMzMrgpJNO4uGHH+awww5DEldeeSX77bcfP/nJT7jqqquora2lT58+3Hzzzbz88sucdtppNDU1AfDd7363zNHvuja7oU47lpsWEfNKF1Lb3A21Wffibqg7X6d2Q50+RXxW54VnZma7m2KuEfxG0t9LOkDS3s2fYlYuabKkZyStknRBgTJfkLRS0pPphWgzMyuhYq4RND8v8M2caQGMbGshSdXAtcBfkjyRvETSgohYmVPmQOAfgKMi4k+S9ulI8GbWPURE3pe/W8ftytt+200EETFil6KBCcCqiFgNIGkuMBVYmVPmDODaiPhTui0/sWxWYerq6ti4cSMDBgxwMviAIoKNGzdSV1fXfuEcxTxZ/OUCG7y5nUWHAGtyxpv7Kcr1kXQb/0vygvtLIuLePDHMIu3faNiwYe2FbGZdyNChQ2loaGD9+vXlDqVbqKurY+jQoR1appimocNztwEcCzwGtJcI8qX21ucsNcCBwCSSJ5YfkDQ6InZ4VjsiZgOzIblrqIiYzayLqK2tZcSIXW14sM5QTNPQ2bnjkvYk6XaiPQ3AATnjQ4G1ecosjoitwAuSniFJDEuKWL+ZmXWCYu4aam0TSWXdniXAgZJGSNoDmE7yQFquXwDHAEgaSNJU5HcdmJmVUDHXCH7J9iadKuAQoN0HzCJim6SzSPolqgbmRMSTki4FlkbEgnTepyStBBqB8yJi4679KWZmtivafLIYQNLROaPbgJcioiHTqNrgJ4vNzDqurSeLi7lY/EfglYjYkq6sp6ThEfFiJ8ZoZmZlUsw1gp8DTTnjjek0MzPrBopJBDUR8X7zSDq8R3YhmZlZKRWTCNZLOrF5RNJUYEN2IZmZWSkVc43g68Atkn6YjjcAeZ82NjOzrqeYB8qeB46U1IfkLiO/r9jMrBtpt2lI0r9J2isi3omItyX1l/QvpQjOzMyyV8w1gim5ff+kPYWekF1IZmZWSsUkgmpJPZpHJPUEerRR3szMupBiLhb/F/A7STeSdDXxVdrvedTMzLqIYi4WXylpOXAcSdfSl0XEfZlHZmZmJVHMGQHpy2LuBZB0lKRrI+Kb7SxmZmZdQFGJQNJYYAZwCvACcEeWQZmZWekUTASSPkLyDoEZwEbgNpLnCI4pUWxmZlYCbZ0RPA08AHwmIlYBSPp2SaLKwj0XwKtPlDsKM7Ndt9+hMOXyTl9tW7ePngy8CiyU9GNJx5L/PcRmZtaFFTwjiIg7gTsl9QY+C3wb2FfSdcCdEfHf7a1c0mTg+yRvKLshIvKmMknTSLq2PjwisnnrTAZZ1MysO2j3gbKIeDcibomIvyJ5Af0y4IL2lpNUDVwLTCF5veUMSYfkKdcXOAd4pIOxm5lZJ+jQy+sj4vWI+I+I+Isiik8AVkXE6vQdBnOBqXnKXQZcCWzpSCxmZtY5OpQIOmgIsCZnvCGd1kLSOOCAiPhVWyuSNEvSUklL169f3/mRmplVsCwTQb4Ly9EyU6oCvgf8XXsriojZEVEfEfWDBg3qxBDNzCzLRNAAHJAzPhRYmzPeFxgN3C/pReBIYIGk+gxjMjOzVrJMBEuAAyWNkLQHycNpC5pnRsSbETEwIoZHxHBgMXBiZncNmZlZXpklgojYBpwF3Ac8BcyLiCclXZr7DmQzMyuvovoa2lURcTdwd6tpFxUoOynLWMzMLL8sm4bMzKwLcCIwM6twTgRmZhXOicDMrMI5EZiZVTgnAjOzCudEYGZW4ZwIzMwqnBOBmVmFcyIwM6twTgRmZhXOicDMrMI5EZiZVTgnAjOzCudEYGZW4ZwIzMwqXKaJQNJkSc9IWiXpgjzz/1bSSknLJf1O0oeyjMfMzHaWWSKQVA1cC0wBDgFmSDqkVbH/A+ojYgwwH7gyq3jMzCy/LM8IJgCrImJ1RLwPzAWm5haIiIURsSkdXQwMzTAeMzPLI8tEMARYkzPekE4r5HTgnnwzJM2StFTS0vXr13diiGZmlmUiUJ5pkbegdCpQD1yVb35EzI6I+oioHzRoUCeGaGZmNRmuuwE4IGd8KLC2dSFJxwEXAkdHxHsZxmNmZnlkeUawBDhQ0ghJewDTgQW5BSSNA/4DODEi1mUYi5mZFZBZIoiIbcBZwH3AU8C8iHhS0qWSTkyLXQX0AX4uaZmkBQVWZ2ZmGcmyaYiIuBu4u9W0i3KGj8ty+2Zm1j4/WWxmVuGcCMzMKpwTgZlZhXMiMDOrcE4EZmYVzonAzKzCZXr7qJnZ7iYi2NYUbGsMtjY1sa0x2Nb83TzcFGxtbJ4XbGvcPq2xKdialmsZbmxia1PQ2FJu+zIt627aXq5lXrqerY2Rrisp29i0PbbmbW5rCqYffgB/c/SHO32fOBGYWV4R2yu85opqe4WXr6JqSivA3Mpve4W3taViTCvCdB3JupJpuZVsss3mcrmV586V6E6VbXO8rSvZpmS4lKqrRE2VqK2uorpK1FaLmqqc4eoqaqpETTq9eX6P2pp0elXL93571mUSoxOBWSeICLZsbeL9xqacI8HtlVKhiqq5Mm3MqdB2qHRbVaa56y7+iHV7ZdqYU3nnVqb5jlhLXF9SU6W0cqxqqRSbK8jatDLMnV9bVUVNVRV1tTtXssnySeVZW7VzZdsyLy1XnVOutlpp5b19uDanMm4dU8v2crZdmxODlK//zd2LE4EZsK2xibe3bOPtLdt4a8vW5LN5G29v2cpbW9LvlvGtLeXe3rKNtzYn39tKVHO2VERpZVPdfBSZTqtuVaHVVlWxR00VvVoqru2VafP83Iozdz07HLHusN6qNivdfJVyvm02V+BdpcLsrpwIrMuLCDZvbdyhon4rp4JuXWHnG9/0fmO72+m9RzX9etbSt66GfnW1DOrTgw8P6tMy3qeuhj2qq3KOaHOOEPNWjm1UurnNBDkVcbUrTMuAE4GVXfPReG4F/VbBCjw9Mn9vxyP29tp9a6tF37pa+tXVJN89axjUpw/9eqbjdWkFn1PR962rYc90vE+PGmqqfZOddU9OBPaBRASb3m/cqaJ+K2+TSvP4jkfmxRyN9+lRs0Mlvk/fOv5s0PbxQpV5v3S8R02Vj6TNCnAiqHBbm4/G8xx151bmeZtW0u9ijsb71dXuUEHv26+u4FH4jhV50uRSXeVK3CwrTgRdWETw7vuN+S9kttm8sn1889b2j8b79qjZoYLer18dB+7TugLPPTLffqTer85H42a7OyeCMnp/W9P2o+08FfbOFzx3bB9/5732j8b3qK7aqYIevGcdfXvkq7h3PjLv08NH42bdXaaJQNJk4PtANXBDRFzean4P4GbgY8BG4JSIeDHLmDpL89F43op6y/aj8bbax7dsbWp3OztUzHW17L9XHX3r+u5w1J3bPt66aaWutroEe8PMurLMEoGkauBa4C9JXmS/RNKCiFiZU+x04E8R8WeSpgNXAKdkFVOu5qPxgveIt9O08vaWre0+cLNHTVXLBcu+PZPv/ffsub2y7tFG+3jPWvrsUUOVj8bNLGNZnhFMAFZFxGoASXOBqUBuIpgKXJIOzwd+KEkR0elP5tz/zDou+9XKloq/vaNxqflOle0V8/571XFQXd88Fzh3bmbpW1fjo3Ez6xKyTARDgDU54w3AEYXKRMQ2SW8CA4ANuYUkzQJmAQwbNmyXgunXs5aD9uuX94Jm0l6+4xG5j8bNrFJkmQjy1aKtj/SLKUNEzAZmA9TX1+/S2cL4Yf0Z/8X+u7KomVm3luWjkg3AATnjQ4G1hcpIqgH2BF7PMCYzM2sly0SwBDhQ0ghJewDTgQWtyiwAvpIOTwN+n8X1ATMzKyyzpqG0zf8s4D6S20fnRMSTki4FlkbEAuA/gZ9KWkVyJjA9q3jMzCy/TJ8jiIi7gbtbTbsoZ3gL8PksYzAzs7a5O0UzswrnRGBmVuGcCMzMKpwTgZlZhVNXu1tT0nrgpV1cfCCtnlreTeyuccHuG5vj6hjH1THdMa4PRcSgfDO6XCL4ICQtjYj6csfR2u4aF+y+sTmujnFcHVNpcblpyMyswjkRmJlVuEpLBLPLHUABu2tcsPvG5rg6xnF1TEXFVVHXCMzMbGeVdkZgZmatOBGYmVW4bpMIJE2W9IykVZIuyDO/h6Tb0vmPSBqeM+8f0unPSDq+xHH9raSVkpZL+p2kD+XMa5S0LP207sI767hmSlqfs/2v5cz7iqTn0s9XWi+bcVzfy4npWUlv5MzLcn/NkbRO0ooC8yXpB2ncyyWNz5mX5f5qL64vpvEsl/SQpMNy5r0o6Yl0fy0tcVyTJL2Z8+91Uc68Nn8DGcd1Xk5MK9Lf1N7pvEz2l6QDJC2U9JSkJyWdm6dMtr+viOjyH5Jurp8HRgJ7AI8Dh7Qq8w3g+nR4OnBbOnxIWr4HMCJdT3UJ4zoG6JUOn9kcVzr+Thn310zgh3mW3RtYnX73T4f7lyquVuXPJunePNP9la57IjAeWFFg/gnAPSRv3TsSeCTr/VVkXB9v3h4wpTmudPxFYGCZ9tck4Fcf9DfQ2XG1KvsZknekZLq/gMHA+HS4L/Bsnv+Pmf6+ussZwQRgVUSsjoj3gbnA1FZlpgI/SYfnA8dKUjp9bkS8FxEvAKvS9ZUkrohYGBGb0tHFJG9yy1ox+6uQ44HfRMTrEfEn4DfA5DLFNQO4tZO23aaIWETbb8+bCtwcicXAXpIGk+3+ajeuiHgo3S6U7vdVzP4q5IP8Njs7rpL8viLilYh4LB1+G3iK5H3uuTL9fXWXRDAEWJMz3sDOO7KlTERsA94EBhS5bJZx5TqdJOs3q5O0VNJiSZ/tpJg6EtfJ6WnofEnNrx3dLfZX2oQ2Avh9zuSs9lcxCsWe5f7qqNa/rwD+W9KjkmaVIZ4/l/S4pHskjUqn7Rb7S1Ivkgr19pzJme8vJU3W44BHWs3K9PeV6YtpSkh5prW+L7ZQmWKW3VVFr1vSqUA9cHTO5GERsVbSSOD3kp6IiOdLFNcvgVsj4j1JXyc5m/qLIpfNMq5m04H5EdGYMy2r/VWMcvy+iibpGJJE8ImcyUel+2sf4DeSnk6PmEvhMZK+b96RdALwC+BAdpP9RdIs9L8RkXv2kOn+ktSHJPF8KyLeaj07zyKd9vvqLmcEDQHVDVoAAAIXSURBVMABOeNDgbWFykiqAfYkOUUsZtks40LSccCFwIkR8V7z9IhYm36vBu4nOVIoSVwRsTEnlh8DHyt22SzjyjGdVqftGe6vYhSKPcv9VRRJY4AbgKkRsbF5es7+WgfcSec1ibYrIt6KiHfS4buBWkkD2Q32V6qt31en7y9JtSRJ4JaIuCNPkWx/X5194aMcH5Izm9UkTQXNF5hGtSrzTXa8WDwvHR7FjheLV9N5F4uLiWscycWxA1tN7w/0SIcHAs/RSRfNioxrcM7wScDi2H5x6oU0vv7p8N6liist91GSC3cqxf7K2cZwCl/8/DQ7Xsz7Q9b7q8i4hpFc9/p4q+m9gb45ww8Bk0sY137N/34kFeof031X1G8gq7jS+c0Hib1Lsb/Sv/tm4Jo2ymT6++q0nVvuD8lV9WdJKtUL02mXkhxlA9QBP0//U/wBGJmz7IXpcs8AU0oc12+B14Bl6WdBOv3jwBPpf4QngNNLHNd3gSfT7S8EDspZ9qvpflwFnFbKuNLxS4DLWy2X9f66FXgF2EpyFHY68HXg6+l8AdemcT8B1Jdof7UX1w3An3J+X0vT6SPTffV4+u98YYnjOivn97WYnESV7zdQqrjSMjNJbiDJXS6z/UXSXBfA8px/pxNK+ftyFxNmZhWuu1wjMDOzXeREYGZW4ZwIzMwqnBOBmVmFcyIwM6twTgRmZhXOicDMrML9fziTPrR1t4JIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-4\n",
    "epochs = 3\n",
    "decoder_optimizer = torch.optim.Adam(rnn_decoder.parameters(), lr = lr)\n",
    "encoder_optimizer = torch.optim.Adam(rnn_encoder.parameters(), lr = lr)\n",
    "from chamfer_distance_loss import MyChamferDistance\n",
    "loss = MyChamferDistance()\n",
    "\n",
    "loss_history, train_history, val_history = train_model(\n",
    "    encoder = rnn_encoder, \n",
    "    decoder = rnn_decoder, \n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    loss = loss,\n",
    "    decoder_opt = decoder_optimizer,\n",
    "    encoder_opt = encoder_optimizer,\n",
    "    epochs = epochs)\n",
    "\n",
    "plot_history(loss_history, train_history, val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 61% | 70% |\n"
     ]
    }
   ],
   "source": [
    "# https://blog.paperspace.com/pytorch-memory-multi-gpu-debugging/\n",
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: [0]\n",
      "predicted: [1]\n",
      "loss: tensor([1.0033], grad_fn=<AddBackward0>)\n",
      "accuracy: [1]\n",
      "1 ------------------------------\n",
      "actual: [0]\n",
      "predicted: [1]\n",
      "loss: tensor([1.2233], grad_fn=<AddBackward0>)\n",
      "accuracy: [1]\n",
      "2 ------------------------------\n",
      "actual: [0]\n",
      "predicted: [2]\n",
      "loss: tensor([1.1961], grad_fn=<AddBackward0>)\n",
      "accuracy: [0]\n",
      "3 ------------------------------\n",
      "actual: [100]\n",
      "predicted: [0]\n",
      "loss: tensor([1.1707], grad_fn=<AddBackward0>)\n",
      "accuracy: [0]\n",
      "4 ------------------------------\n",
      "actual: [3]\n",
      "predicted: [1109]\n",
      "loss: tensor([2.6501], grad_fn=<AddBackward0>)\n",
      "accuracy: [0.14638662338256836]\n",
      "5 ------------------------------\n"
     ]
    }
   ],
   "source": [
    "from train import calculate_accuracy\n",
    "i = 0\n",
    "for (x, y) in iter(val_loader):\n",
    "    outs, learned = rnn_encoder(x)\n",
    "    decoded = rnn_decoder(outs, learned)\n",
    "    \n",
    "    yyy = []\n",
    "    for yy in y:\n",
    "        yyy.append(yy.shape[0])\n",
    "    ppp = []\n",
    "    for dd in decoded:\n",
    "        ppp.append(dd.shape[0])\n",
    "    \n",
    "    print('actual:', yyy)\n",
    "    print('predicted:', ppp)\n",
    "    \n",
    "    lv = loss(decoded, y)\n",
    "    print ('loss:', lv)\n",
    "\n",
    "    acc = calculate_accuracy(decoded, y)\n",
    "    print('accuracy:', acc)\n",
    "\n",
    "    i += 1\n",
    "    print(i, '------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5         6         7    8\n",
      "0  0.0  0.0  1.0  0.0  0.0  1.0  0.704550  0.993571  0.0\n",
      "1  0.0  0.0  1.0  0.0  0.0  1.0  0.032872  0.076172  0.0\n",
      "2  0.0  0.0  1.0  0.0  0.0  1.0  0.034243  0.032112  0.0\n",
      "3  0.0  0.0  1.0  0.0  0.0  1.0  0.034243  0.024829  0.0\n",
      "4  0.0  0.0  1.0  0.0  0.0  1.0  0.034243  0.053349  0.0\n",
      "3\n",
      "          0    1         2         3         4         5\n",
      "0  0.000000  0.0  0.363057  0.000000  0.000000  0.000000\n",
      "1  0.081114  0.0  0.000000  0.081783  1.000000  0.333333\n",
      "2  1.000000  1.0  1.000000  1.000000  0.781558  1.000000\n",
      "1109\n",
      "          0         1         2         3         4         5\n",
      "0 -0.735503  0.242185 -0.010942  0.495159  0.349049  0.107618\n",
      "1 -0.722262  0.200295  0.014158  0.654436  0.261402 -0.082537\n",
      "2 -0.721498  0.239717  0.046352  0.683690  0.170664 -0.128214\n",
      "3 -0.734776  0.218683  0.037967  0.686598  0.173362 -0.139842\n",
      "4 -0.731162  0.227371  0.053353  0.692466  0.160976 -0.144932\n"
     ]
    }
   ],
   "source": [
    "ii = pd.DataFrame(x[0].cpu().detach().numpy())\n",
    "print(ii.head())\n",
    "yy = pd.DataFrame(y[0].cpu().detach().numpy())\n",
    "print(len(yy))\n",
    "print(yy.head())\n",
    "pp = pd.DataFrame(decoded[0].cpu().detach().numpy())\n",
    "print(len(pp))\n",
    "print(pp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing: 0.041\n"
     ]
    }
   ],
   "source": [
    "from train import calculate_accuracy\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "rnn_encoder.eval()\n",
    "rnn_decoder.eval()\n",
    "\n",
    "test_accuracies = []\n",
    "for (x,y) in test_loader:\n",
    "    with torch.no_grad():\n",
    "        out, hidden = rnn_encoder(x)\n",
    "        prediction = rnn_decoder(out, hidden)\n",
    "        accuracy = calculate_accuracy(prediction, y)\n",
    "        test_accuracies.append(accuracy)\n",
    "        \n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print('Accuracy on testing: {0:2.3f}'.format(mean_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
