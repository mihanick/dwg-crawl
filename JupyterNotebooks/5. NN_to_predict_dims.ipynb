{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "The idea is that we predict rotated linear dimension position from lines and text from the drawing.\n",
    "\n",
    "# Thoughts\n",
    "Basic logic is we split dataset to input lines or texts positions StartPoint, EndPoint, Position XYZ and predict dimension extension line poistion XLine1Point, XLine2Point XYZ.\n",
    "\n",
    "We going to group samples by FileId. That is each sample will contain variable length data (attributes of variable number of  lines and text) and variable output data (variable number of dimensions).\n",
    "\n",
    "I intend to [use RNN for it](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from processing import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassName</th>\n",
       "      <th>FileId</th>\n",
       "      <th>XLine1Point.X</th>\n",
       "      <th>XLine1Point.Y</th>\n",
       "      <th>XLine1Point.Z</th>\n",
       "      <th>XLine2Point.X</th>\n",
       "      <th>XLine2Point.Y</th>\n",
       "      <th>XLine2Point.Z</th>\n",
       "      <th>StartPoint.X</th>\n",
       "      <th>StartPoint.Y</th>\n",
       "      <th>StartPoint.Z</th>\n",
       "      <th>EndPoint.X</th>\n",
       "      <th>EndPoint.Y</th>\n",
       "      <th>EndPoint.Z</th>\n",
       "      <th>Position.X</th>\n",
       "      <th>Position.Y</th>\n",
       "      <th>Position.Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>867872</th>\n",
       "      <td>AcDbText</td>\n",
       "      <td>0d9e42c4-bded-4dd0-9bbb-d4abad30410e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>621037.257604</td>\n",
       "      <td>12177.425365</td>\n",
       "      <td>-17504.791854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310838</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>6f4a5e84-b45f-4d1f-9d80-a3a0d159c145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.103418e+02</td>\n",
       "      <td>340.502524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.103418e+02</td>\n",
       "      <td>350.418200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447789</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>50f2c8eb-f9f2-4470-a9d0-2df65db33347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.584164e+06</td>\n",
       "      <td>664570.788057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.584164e+06</td>\n",
       "      <td>664545.788289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222199</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>33cac39f-f024-40d4-98c9-d94554cfe7cf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.793491e+03</td>\n",
       "      <td>461.181698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.793491e+03</td>\n",
       "      <td>461.179070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388506</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>7c0e80ee-c625-4601-bf74-4f689aace0b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.404816e+02</td>\n",
       "      <td>472.590296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.404816e+02</td>\n",
       "      <td>472.590296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688070</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>6a359cb6-c992-44da-87e2-a277a928a525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.055062e+05</td>\n",
       "      <td>-87863.162449</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>-1.056038e+05</td>\n",
       "      <td>-87895.604995</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726705</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>1c68b718-fb88-4678-9c2e-512776ea79dd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.829456e+06</td>\n",
       "      <td>-703357.579645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.829456e+06</td>\n",
       "      <td>-701517.579645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432628</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>7cdbf03f-a841-41a9-8279-5fd0da031a6d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.516576e+03</td>\n",
       "      <td>636.108325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.515976e+03</td>\n",
       "      <td>636.108325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458942</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>5b508844-6c5a-41de-a401-899f3c9ba6f9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.570462e+03</td>\n",
       "      <td>1481.669321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.570462e+03</td>\n",
       "      <td>1482.329321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>AcDbLine</td>\n",
       "      <td>3b99b670-4d2d-401b-8b19-ed93c374eb34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.210245e+05</td>\n",
       "      <td>-241946.029998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.212311e+05</td>\n",
       "      <td>-241946.029998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9180 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ClassName                                FileId  XLine1Point.X  \\\n",
       "867872  AcDbText  0d9e42c4-bded-4dd0-9bbb-d4abad30410e            NaN   \n",
       "310838  AcDbLine  6f4a5e84-b45f-4d1f-9d80-a3a0d159c145            NaN   \n",
       "447789  AcDbLine  50f2c8eb-f9f2-4470-a9d0-2df65db33347            NaN   \n",
       "222199  AcDbLine  33cac39f-f024-40d4-98c9-d94554cfe7cf            NaN   \n",
       "388506  AcDbLine  7c0e80ee-c625-4601-bf74-4f689aace0b3            NaN   \n",
       "...          ...                                   ...            ...   \n",
       "688070  AcDbLine  6a359cb6-c992-44da-87e2-a277a928a525            NaN   \n",
       "726705  AcDbLine  1c68b718-fb88-4678-9c2e-512776ea79dd            NaN   \n",
       "432628  AcDbLine  7cdbf03f-a841-41a9-8279-5fd0da031a6d            NaN   \n",
       "458942  AcDbLine  5b508844-6c5a-41de-a401-899f3c9ba6f9            NaN   \n",
       "6212    AcDbLine  3b99b670-4d2d-401b-8b19-ed93c374eb34            NaN   \n",
       "\n",
       "        XLine1Point.Y  XLine1Point.Z  XLine2Point.X  XLine2Point.Y  \\\n",
       "867872            NaN            NaN            NaN            NaN   \n",
       "310838            NaN            NaN            NaN            NaN   \n",
       "447789            NaN            NaN            NaN            NaN   \n",
       "222199            NaN            NaN            NaN            NaN   \n",
       "388506            NaN            NaN            NaN            NaN   \n",
       "...               ...            ...            ...            ...   \n",
       "688070            NaN            NaN            NaN            NaN   \n",
       "726705            NaN            NaN            NaN            NaN   \n",
       "432628            NaN            NaN            NaN            NaN   \n",
       "458942            NaN            NaN            NaN            NaN   \n",
       "6212              NaN            NaN            NaN            NaN   \n",
       "\n",
       "        XLine2Point.Z  StartPoint.X   StartPoint.Y  StartPoint.Z  \\\n",
       "867872            NaN           NaN            NaN           NaN   \n",
       "310838            NaN  2.103418e+02     340.502524           0.0   \n",
       "447789            NaN  1.584164e+06  664570.788057           0.0   \n",
       "222199            NaN  5.793491e+03     461.181698           0.0   \n",
       "388506            NaN  7.404816e+02     472.590296           0.0   \n",
       "...               ...           ...            ...           ...   \n",
       "688070            NaN -1.055062e+05  -87863.162449       10800.0   \n",
       "726705            NaN  1.829456e+06 -703357.579645           0.0   \n",
       "432628            NaN  1.516576e+03     636.108325           0.0   \n",
       "458942            NaN  2.570462e+03    1481.669321           0.0   \n",
       "6212              NaN  4.210245e+05 -241946.029998           0.0   \n",
       "\n",
       "          EndPoint.X     EndPoint.Y  EndPoint.Z     Position.X    Position.Y  \\\n",
       "867872           NaN            NaN         NaN  621037.257604  12177.425365   \n",
       "310838  2.103418e+02     350.418200         0.0            NaN           NaN   \n",
       "447789  1.584164e+06  664545.788289         0.0            NaN           NaN   \n",
       "222199  5.793491e+03     461.179070         0.0            NaN           NaN   \n",
       "388506  7.404816e+02     472.590296         0.0            NaN           NaN   \n",
       "...              ...            ...         ...            ...           ...   \n",
       "688070 -1.056038e+05  -87895.604995     10800.0            NaN           NaN   \n",
       "726705  1.829456e+06 -701517.579645         0.0            NaN           NaN   \n",
       "432628  1.515976e+03     636.108325         0.0            NaN           NaN   \n",
       "458942  2.570462e+03    1482.329321         0.0            NaN           NaN   \n",
       "6212    4.212311e+05 -241946.029998         0.0            NaN           NaN   \n",
       "\n",
       "          Position.Z  \n",
       "867872 -17504.791854  \n",
       "310838           NaN  \n",
       "447789           NaN  \n",
       "222199           NaN  \n",
       "388506           NaN  \n",
       "...              ...  \n",
       "688070           NaN  \n",
       "726705           NaN  \n",
       "432628           NaN  \n",
       "458942           NaN  \n",
       "6212             NaN  \n",
       "\n",
       "[9180 rows x 17 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_pickle('test_dataset.pickle')\n",
    "# BUG: Dataset is filtered, we need all data from SOME files, not SOME data from All Files\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [\n",
    "    #'ClassName', \n",
    "    'StartPoint.X', 'StartPoint.Y', 'StartPoint.Z',\n",
    "    'EndPoint.X', 'EndPoint.Y', 'EndPoint.Z',\n",
    "    'Position.X', 'Position.Y', 'Position.Z']\n",
    "\n",
    "y_columns = [\n",
    "    #'ClassName', \n",
    "    'XLine1Point.X', 'XLine1Point.Y','XLine1Point.Z', \n",
    "    'XLine2Point.X', 'XLine2Point.Y', 'XLine2Point.Z']\n",
    "\n",
    "ent_features = len(x_columns)\n",
    "dim_features = len(y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityDataset(Dataset):\n",
    "    def __init__(self, pandasData):\n",
    "        self.data = pandasData\n",
    "        self.groupped = pandasData.groupby('FileId')\n",
    "        self.keys = list(self.groupped.groups.keys() )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # https://stackoverflow.com/questions/45147100/pandas-drop-columns-with-all-nans\n",
    "        \n",
    "        x = self.groupped.get_group(self.keys[index])[x_columns]\n",
    "        x = x.dropna( how ='all')\n",
    "        y = self.groupped.get_group(self.keys[index])[y_columns]\n",
    "        y = y.dropna(how = 'all')\n",
    "        #print(self.keys[index])\n",
    "        # if not y.empty:\n",
    "        #    print(x, y)\n",
    "        \n",
    "        return torch.tensor(np.array(x.values)), torch.tensor(np.array(y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 9]) torch.Size([0, 6])\n"
     ]
    }
   ],
   "source": [
    "entities = EntityDataset(test_data)\n",
    "for c,d in entities:\n",
    "    print(c.shape, d.shape)\n",
    "    # print('0000000000000000000000000000000000000')\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "data_len = len(entities)\n",
    "\n",
    "validation_fraction = 0.2\n",
    "test_fraction       = 0.3\n",
    "\n",
    "val_split  = int(np.floor(validation_fraction * data_len))\n",
    "test_split = int(np.floor(test_fraction * data_len))\n",
    "indices = list(range(data_len))\n",
    "np.random.seed(228)\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_indices   = indices[:val_split]\n",
    "test_indices  = indices[val_split:test_split]\n",
    "train_indices = indices[test_split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler   = SubsetRandomSampler(val_indices)\n",
    "test_sampler  = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# https://stackoverflow.com/questions/64586575/adding-class-objects-to-pytorch-dataloader-batch-must-contain-tensors\n",
    "def custom_collate(sample):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for (xx, yy) in sample:\n",
    "        #if torch.count_nonzero(xx) > 0:\n",
    "            # print(xx)\n",
    "        x.append(xx)\n",
    "        #if torch.count_nonzero(yy) > 0:\n",
    "        y.append(yy)\n",
    "    #print(len(x), len(y))\n",
    "    return x, y\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(entities, batch_size = batch_size, sampler = train_sampler, collate_fn=custom_collate)\n",
    "val_loader   = torch.utils.data.DataLoader(entities, batch_size = batch_size, sampler = val_sampler, collate_fn=custom_collate)\n",
    "test_loader  = torch.utils.data.DataLoader(entities, batch_size = batch_size, sampler = test_sampler, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([0, 6])\n",
      "torch.Size([0, 6])\n"
     ]
    }
   ],
   "source": [
    "(a,b) = next(iter(train_loader))\n",
    "print(len(a),len(b))\n",
    "for (x,y) in iter(train_loader):\n",
    "    for xx in x:\n",
    "        print(xx.shape)\n",
    "        pass\n",
    "    for yy in y:\n",
    "        print(yy.shape)\n",
    "    # print(a.shape,b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnEncoder(nn.Module):\n",
    "    def __init__(self, ent_features, learned_size, n_neurons = 16):\n",
    "        super(RnnEncoder, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size = ent_features, hidden_size = learned_size)\n",
    "        self.learned_size = learned_size\n",
    "        self.ent_features = ent_features\n",
    "        \n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(learned_size, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def init_hidden(self,batch_size):\n",
    "        self.hidden = torch.zeros(1, batch_size, self.learned_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input of shape (seq_len, batch, input_size)\n",
    "        batch_size = len(x)\n",
    "        \n",
    "        hiddens = torch.zeros([batch_size, self.learned_size], dtype = torch.float32, device = device)\n",
    "        outs = torch.zeros([batch_size, 1], dtype = torch.int32, device = device)\n",
    "        for j in range(batch_size):\n",
    "            f = x[j]\n",
    "            entities_count = f.shape[0]\n",
    "            self.init_hidden(entities_count)\n",
    "            inp = torch.zeros([entities_count, 1, self.ent_features], dtype = torch.float32, device = device)\n",
    "            # print(inp.shape, f.shape)\n",
    "            inp[:,0,:] = f[:,:]\n",
    "            \n",
    "            outp, h_n = self.rnn(inp)\n",
    "            # print('h_N', h_n.shape)\n",
    "            # print('cell out', outp.shape)\n",
    "            n = self.fcn(outp)\n",
    "            \n",
    "            # https://stackoverflow.com/questions/48005152/extract-the-count-of-positive-and-negative-values-from-an-array\n",
    "            cou = np.sum(np.array(n.detach().numpy()) > 0, axis = 0)\n",
    "            # print(cou)\n",
    "            outs[j] = torch.tensor(cou) \n",
    "            hiddens[j] = h_n\n",
    "            j = j + 1\n",
    "                \n",
    "        return outs, hiddens\n",
    "            \n",
    "class RnnDecoder(nn.Module):\n",
    "    def __init__(self, learned_size, dim_features):\n",
    "        super(RnnDecoder, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size = learned_size, hidden_size = dim_features)\n",
    "        self.learned_size = learned_size\n",
    "        self.dim_features = dim_features\n",
    "        \n",
    "    def forward(self, x, out_counts):\n",
    "        '''Receives tensor with hidden state and number of dimensions tensor per each file.\n",
    "            Returns a list of tensors with dimension parameters'''\n",
    "        # input of shape (seq_len, batch, input_size)\n",
    "        \n",
    "        result = []\n",
    "        for j in range(batch_size):\n",
    "            dim_count = out_counts[j]\n",
    "            outs = torch.zeros([dim_count,dim_features])\n",
    "            if dim_count > 0:\n",
    "                inp = torch.zeros([dim_count, 1, self.learned_size], dtype=torch.float32, device = device)\n",
    "                xj = x[j]\n",
    "                # print(inp.shape, xj.shape)\n",
    "                inp[:,0] = xj\n",
    "                outs, hiddens = self.rnn(inp)\n",
    "                print(\"decoder outs.shape\", outs.shape)\n",
    "                # we remove batch dimension, as batches here are list\n",
    "                # https://pytorch.org/docs/stable/generated/torch.squeeze.html\n",
    "                outs = outs.squeeze(dim = 1)\n",
    "            result.append(outs)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs x: 2 x torch.Size([1, 9]) y: 2 x torch.Size([0, 6])\n",
      "learned shape: torch.Size([2, 1024])\n",
      "outs shape: torch.Size([2, 1]) outs_value tensor([[42],\n",
      "        [ 0]], dtype=torch.int32)\n",
      "decoder outs.shape torch.Size([42, 1, 6])\n",
      "decoded: 2 x torch.Size([42, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "rnn_encoder = RnnEncoder(ent_features, 1024).to(device)\n",
    "rnn_decoder = RnnDecoder(1024, dim_features).to(device)\n",
    "(x,y) = next(iter(train_loader))\n",
    "print('inputs','x:',len(x),'x',x[0].shape,'y:',len(y),'x',y[0].shape)\n",
    "outs_numbers, learned = rnn_encoder(x)\n",
    "print('learned shape:', learned.shape)\n",
    "print(\"outs shape:\", outs.shape, 'outs_value', outs)\n",
    "# make sure something is passed\n",
    "outs[0] = 42\n",
    "decoded = rnn_decoder(learned, outs)\n",
    "print('decoded:',len(decoded),'x', decoded[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as LA\n",
    "# https://stackoverflow.com/questions/47060685/chamfer-distance-between-two-point-clouds-in-tensorflow\n",
    "def array2samples_distance(array1, array2):\n",
    "    \"\"\"\n",
    "    arguments: \n",
    "        array1: the array, size: (num_point, num_feature)\n",
    "        array2: the samples, size: (num_point, num_feature)\n",
    "    returns:\n",
    "        distances: each entry is the distance from a sample to array1 \n",
    "    \"\"\"\n",
    "    num_point, num_features = array1.shape\n",
    "    expanded_array1 = np.tile(array1, (num_point, 1))\n",
    "    expanded_array2 = np.reshape(\n",
    "            np.tile(np.expand_dims(array2, 1), \n",
    "                    (1, num_point, 1)),\n",
    "            (-1, num_features))\n",
    "    distances = LA.norm(expanded_array1-expanded_array2, axis=1)\n",
    "    distances = np.reshape(distances, (num_point, num_point))\n",
    "    distances = np.min(distances, axis=1)\n",
    "    distances = np.mean(distances)\n",
    "    return distances\n",
    "\n",
    "def chamfer_distance_numpy(array1, array2):\n",
    "    batch_size, num_point, num_features = array1.shape\n",
    "    dist = 0\n",
    "    for i in range(batch_size):\n",
    "        av_dist1 = array2samples_distance(array1[i], array2[i])\n",
    "        av_dist2 = array2samples_distance(array2[i], array1[i])\n",
    "        dist = dist + (av_dist1+av_dist2)/batch_size\n",
    "    return dist\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "def chamfer_distance_sklearn(array1,array2):\n",
    "    batch_size, num_point = array1.shape[:2]\n",
    "    dist = 0\n",
    "    for i in range(batch_size):\n",
    "        tree1 = KDTree(array1[i], leaf_size=num_point+1)\n",
    "        tree2 = KDTree(array2[i], leaf_size=num_point+1)\n",
    "        distances1, _ = tree1.query(array2[i])\n",
    "        distances2, _ = tree2.query(array1[i])\n",
    "        av_dist1 = np.mean(distances1)\n",
    "        av_dist2 = np.mean(distances2)\n",
    "        dist = dist + (av_dist1+av_dist2)/batch_size\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 6])\n",
      "torch.Size([1, 42, 6])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1764,6) (168,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-cab175e230ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_chamfer_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mChamferDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-338-cab175e230ab>\u001b[0m in \u001b[0;36mmy_chamfer_distance\u001b[0;34m(out, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchamfer_distance_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myyy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-336-f83442779e68>\u001b[0m in \u001b[0;36mchamfer_distance_numpy\u001b[0;34m(array1, array2)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mav_dist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray2samples_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mav_dist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray2samples_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mav_dist1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mav_dist2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-336-f83442779e68>\u001b[0m in \u001b[0;36marray2samples_distance\u001b[0;34m(array1, array2)\u001b[0m\n\u001b[1;32m     15\u001b[0m                     (1, num_point, 1)),\n\u001b[1;32m     16\u001b[0m             (-1, num_features))\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_array1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mexpanded_array2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1764,6) (168,6) "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def my_chamfer_distance(out, y):\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        # we need extra dimension for batch\n",
    "        xxx = torch.unsqueeze(decoded[i], dim = 0)\n",
    "        yyy = torch.unsqueeze(y[i],dim = 0)    \n",
    "        print(yyy.shape)\n",
    "        print(xxx.shape)    \n",
    "\n",
    "        if xxx.shape[1] == 0 and yyy.shape[1] == 0:\n",
    "            loss += 0\n",
    "            continue\n",
    "        if xxx.shape[1] == 0:\n",
    "            loss += math.inf\n",
    "            continue\n",
    "        if yyy.shape[1] == 0:\n",
    "            loss -= math.inf\n",
    "            continue\n",
    "\n",
    "        loss += chamfer_distance_numpy(xxx.detach().numpy(), yyy.detach().numpy()).sum()\n",
    "    return loss\n",
    "\n",
    "# print(my_chamfer_distance(decoded, y))\n",
    "a = [torch.randn([3,6]), torch.randn([2,6])]\n",
    "b = [torch.randn([4,6]), torch.randn([1,6])]\n",
    "print(my_chamfer_distance(a,b))\n",
    "\n",
    "class ChamferDistance(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return my_chamfer_distance(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(loss_history, train_history, val_history):\n",
    "    plt.ylabel('Accuracy @ epoch')\n",
    "    \n",
    "    train, = plt.plot(train_history)\n",
    "    train.set_label(\"train\")\n",
    "    validation, = plt.plot(val_history)\n",
    "    validation.set_label(\"validation\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(encoder, decoder, train_loader, val_loader, loss, decoder_opt,encoder_opt, epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    loss_history = []\n",
    "    train_istory = []\n",
    "    val_history  = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        loss_accumulated = 0\n",
    "        \n",
    "        i_step = 1\n",
    "        for _, (x,y) in enumerate(train_loader):\n",
    "            \n",
    "            decoder_opt.zero_grad()\n",
    "            encoder_opt.zero_grad()\n",
    "            \n",
    "            outs_num, learned = encoder(x)\n",
    "            \n",
    "            decoded = decoder(learned, outs_num)\n",
    "            loss_value = loss(decoded, y)\n",
    "            \n",
    "            loss_value.backward()\n",
    "            decoder_opt.step()\n",
    "            encoder_opt.step()\n",
    "            \n",
    "            loss_accumulated += loss_value\n",
    "            \n",
    "            #val_accuracy = compute_accuracy(model, val_loader)\n",
    "            print('[{0} @ {4} sec] Loss: {1:4f} Train err: {2:2.2f}% Val err: {3:2.2f}%'. format(\n",
    "                epoch,\n",
    "                ave_loss,\n",
    "                (1 - train_accuracy) * 100,\n",
    "                (1 - val_accuracy) * 100,\n",
    "                time.time() - start\n",
    "            ))\n",
    "        \n",
    "        # loss_history.append(float(loss_accum / i_step))\n",
    "        # val_history.append(val_accuracy)\n",
    "        # clear_output(wait=True)\n",
    "        \n",
    "        i_step += 1\n",
    "        \n",
    "    plot_history(loss_history, train_history, val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-329-0f0ea39dede0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdecoder_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mencoder_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     epochs = epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-328-bf410117d277>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(encoder, decoder, train_loader, val_loader, loss, decoder_opt, encoder_opt, epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mdecoder_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mencoder_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 3\n",
    "decoder_optimizer = torch.optim.Adam(rnn_decoder.parameters(), lr = lr)\n",
    "encoder_optimizer = torch.optim.Adam(rnn_encoder.parameters(), lr=lr)\n",
    "loss = ChamferDistance()\n",
    "\n",
    "train_model(\n",
    "    encoder = rnn_encoder, \n",
    "    decoder = rnn_decoder, \n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    loss = loss,\n",
    "    decoder_opt = decoder_optimizer,\n",
    "    encoder_opt = encoder_optimizer,\n",
    "    epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.eval()\n",
    "for (x,y) in test_loader:\n",
    "    with torch.no_grad():\n",
    "        output = model.forward(x.to(device))\n",
    "        accuracy = compute_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
