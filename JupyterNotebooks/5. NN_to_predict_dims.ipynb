{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "The idea is that we predict rotated linear dimension position from lines and text from the drawing.\n",
    "\n",
    "# Thoughts\n",
    "Basic logic is we split dataset to input lines or texts positions StartPoint, EndPoint, Position XYZ and predict dimension extension line poistion XLine1Point, XLine2Point XYZ.\n",
    "\n",
    "We going to group samples by FileId. That is each sample will contain variable length data (attributes of variable number of  lines and text) and variable output data (variable number of dimensions).\n",
    "\n",
    "I intend to [use RNN for it](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DwgDataset\n",
    "batch_size = 1\n",
    "\n",
    "dwg_dataset = DwgDataset(pickle_file = 'test_dataset.pickle', batch_size = batch_size)\n",
    "\n",
    "train_loader = dwg_dataset.train_loader\n",
    "val_loader   = dwg_dataset.val_loader\n",
    "test_loader  = dwg_dataset.test_loader\n",
    "\n",
    "ent_features = dwg_dataset.entities.ent_features\n",
    "dim_features = dwg_dataset.entities.dim_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import RnnDecoder, RnnEncoder\n",
    "rnn_encoder = RnnEncoder(ent_features, 1024, enforced_device = device).to(device)\n",
    "rnn_decoder = RnnDecoder(1024, dim_features, enforced_device = device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_model, plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0-0 @ 0.2 sec] Loss: 3.762907 Train err: 46.6%\n",
      "[0-1 @ 0.2 sec] Loss: 3.569414 Train err: 57.2%\n",
      "[0-2 @ 0.2 sec] Loss: 3.572269 Train err: 57.7%\n",
      "[0-3 @ 0.3 sec] Loss: 3.913982 Train err: 100.0%\n",
      "[0-4 @ 0.4 sec] Loss: 4.578840 Train err: 100.0%\n",
      "[0-5 @ 0.5 sec] Loss: 3.559657 Train err: 56.0%\n",
      "[0-6 @ 0.8 sec] Loss: 3.851068 Train err: 52.6%\n",
      "[0-7 @ 1.0 sec] Loss: 3.564227 Train err: 46.9%\n",
      "[0-8 @ 1.1 sec] Loss: 4.251142 Train err: 68.7%\n",
      "[0-9 @ 1.1 sec] Loss: 3.637224 Train err: 43.9%\n",
      "[0-10 @ 1.7 sec] Loss: 3.505424 Train err: 57.5%\n",
      "[0-11 @ 1.8 sec] Loss: inf Train err: 100.0%\n",
      "[0-12 @ 1.9 sec] Loss: inf Train err: 100.0%\n",
      "[0-13 @ 1.9 sec] Loss: 3.450802 Train err: 52.9%\n",
      "[0-14 @ 3.5 sec] Loss: 4.588172 Train err: 100.0%\n",
      "[0-15 @ 3.6 sec] Loss: 3.780910 Train err: 39.1%\n",
      "[0-16 @ 3.6 sec] Loss: inf Train err: 100.0%\n",
      "[0-17 @ 3.7 sec] Loss: 3.072478 Train err: 100.0%\n",
      "[0-18 @ 3.7 sec] Loss: inf Train err: 100.0%\n",
      "[0-19 @ 4.1 sec] Loss: 4.088762 Train err: 50.8%\n",
      "[0-20 @ 4.2 sec] Loss: inf Train err: 100.0%\n",
      "Epoch [0] validation error: 89.909%\n",
      "[1-0 @ 4.8 sec] Loss: 3.072478 Train err: 100.0%\n",
      "[1-1 @ 4.8 sec] Loss: 3.637224 Train err: 43.9%\n",
      "[1-2 @ 4.8 sec] Loss: 3.913982 Train err: 100.0%\n",
      "[1-3 @ 4.9 sec] Loss: 3.569414 Train err: 57.2%\n",
      "[1-4 @ 4.9 sec] Loss: inf Train err: 100.0%\n",
      "[1-5 @ 5.0 sec] Loss: 4.578840 Train err: 100.0%\n",
      "[1-6 @ 5.1 sec] Loss: inf Train err: 100.0%\n",
      "[1-7 @ 5.7 sec] Loss: 3.505424 Train err: 57.5%\n",
      "[1-8 @ 5.9 sec] Loss: 3.851068 Train err: 52.6%\n",
      "[1-9 @ 7.5 sec] Loss: 4.588172 Train err: 100.0%\n",
      "[1-10 @ 7.8 sec] Loss: 4.088762 Train err: 50.8%\n",
      "[1-11 @ 8.0 sec] Loss: inf Train err: 100.0%\n",
      "[1-12 @ 8.1 sec] Loss: 3.450802 Train err: 52.9%\n",
      "[1-13 @ 8.1 sec] Loss: 3.762907 Train err: 46.6%\n",
      "[1-14 @ 8.2 sec] Loss: inf Train err: 100.0%\n",
      "[1-15 @ 8.2 sec] Loss: 3.572269 Train err: 57.7%\n",
      "[1-16 @ 8.2 sec] Loss: inf Train err: 100.0%\n",
      "[1-17 @ 8.4 sec] Loss: 3.559657 Train err: 56.0%\n",
      "[1-18 @ 8.5 sec] Loss: 4.251142 Train err: 68.7%\n",
      "[1-19 @ 8.7 sec] Loss: 3.564227 Train err: 46.9%\n",
      "[1-20 @ 8.8 sec] Loss: 3.780910 Train err: 39.1%\n",
      "Epoch [1] validation error: 89.909%\n",
      "[2-0 @ 9.3 sec] Loss: inf Train err: 100.0%\n",
      "[2-1 @ 9.3 sec] Loss: 3.072478 Train err: 100.0%\n",
      "[2-2 @ 9.4 sec] Loss: 3.572269 Train err: 57.7%\n",
      "[2-3 @ 9.6 sec] Loss: inf Train err: 100.0%\n",
      "[2-4 @ 9.6 sec] Loss: 3.913982 Train err: 100.0%\n",
      "[2-5 @ 11.2 sec] Loss: 4.588172 Train err: 100.0%\n",
      "[2-6 @ 11.2 sec] Loss: 3.637224 Train err: 43.9%\n",
      "[2-7 @ 11.2 sec] Loss: 3.780910 Train err: 39.1%\n",
      "[2-8 @ 11.3 sec] Loss: inf Train err: 100.0%\n",
      "[2-9 @ 11.6 sec] Loss: 4.088762 Train err: 50.8%\n",
      "[2-10 @ 11.8 sec] Loss: 3.559657 Train err: 56.0%\n",
      "[2-11 @ 12.0 sec] Loss: 3.564227 Train err: 46.9%\n",
      "[2-12 @ 12.1 sec] Loss: 4.251142 Train err: 68.7%\n",
      "[2-13 @ 12.2 sec] Loss: inf Train err: 100.0%\n",
      "[2-14 @ 12.4 sec] Loss: 3.851068 Train err: 52.6%\n",
      "[2-15 @ 12.5 sec] Loss: 3.569414 Train err: 57.2%\n",
      "[2-16 @ 12.6 sec] Loss: 4.578840 Train err: 100.0%\n",
      "[2-17 @ 12.6 sec] Loss: 3.450802 Train err: 52.9%\n",
      "[2-18 @ 12.6 sec] Loss: 3.762907 Train err: 46.6%\n",
      "[2-19 @ 13.3 sec] Loss: 3.505424 Train err: 57.5%\n",
      "[2-20 @ 13.3 sec] Loss: inf Train err: 100.0%\n",
      "Epoch [2] validation error: 89.909%\n",
      "[3-0 @ 14.1 sec] Loss: 4.088762 Train err: 50.8%\n",
      "[3-1 @ 14.2 sec] Loss: 4.578840 Train err: 100.0%\n",
      "[3-2 @ 14.3 sec] Loss: 4.251142 Train err: 68.7%\n",
      "[3-3 @ 14.3 sec] Loss: inf Train err: 100.0%\n",
      "[3-4 @ 14.4 sec] Loss: inf Train err: 100.0%\n",
      "[3-5 @ 14.4 sec] Loss: 3.569414 Train err: 57.2%\n",
      "[3-6 @ 14.6 sec] Loss: inf Train err: 100.0%\n",
      "[3-7 @ 14.7 sec] Loss: 3.572269 Train err: 57.7%\n",
      "[3-8 @ 14.7 sec] Loss: 3.780910 Train err: 39.1%\n",
      "[3-9 @ 14.8 sec] Loss: 3.450802 Train err: 52.9%\n",
      "[3-10 @ 14.9 sec] Loss: 3.559657 Train err: 56.0%\n",
      "[3-11 @ 15.5 sec] Loss: 3.505424 Train err: 57.5%\n",
      "[3-12 @ 15.6 sec] Loss: 3.762907 Train err: 46.6%\n",
      "[3-13 @ 15.8 sec] Loss: 3.564227 Train err: 46.9%\n",
      "[3-14 @ 16.0 sec] Loss: 3.851068 Train err: 52.6%\n",
      "[3-15 @ 17.6 sec] Loss: 4.588172 Train err: 100.0%\n",
      "[3-16 @ 17.7 sec] Loss: 3.072478 Train err: 100.0%\n",
      "[3-17 @ 17.7 sec] Loss: 3.913982 Train err: 100.0%\n",
      "[3-18 @ 17.7 sec] Loss: 3.637224 Train err: 43.9%\n",
      "[3-19 @ 17.8 sec] Loss: inf Train err: 100.0%\n",
      "[3-20 @ 17.9 sec] Loss: inf Train err: 100.0%\n",
      "Epoch [3] validation error: 89.909%\n",
      "[4-0 @ 18.4 sec] Loss: 4.251142 Train err: 68.7%\n",
      "[4-1 @ 18.4 sec] Loss: 3.913982 Train err: 100.0%\n",
      "[4-2 @ 20.0 sec] Loss: 4.588172 Train err: 100.0%\n",
      "[4-3 @ 20.1 sec] Loss: inf Train err: 100.0%\n",
      "[4-4 @ 20.1 sec] Loss: inf Train err: 100.0%\n",
      "[4-5 @ 20.2 sec] Loss: 4.578840 Train err: 100.0%\n",
      "[4-6 @ 20.5 sec] Loss: 3.564227 Train err: 46.9%\n",
      "[4-7 @ 21.1 sec] Loss: 3.505424 Train err: 57.5%\n",
      "[4-8 @ 21.1 sec] Loss: 3.762907 Train err: 46.6%\n",
      "[4-9 @ 21.4 sec] Loss: 4.088762 Train err: 50.8%\n",
      "[4-10 @ 21.7 sec] Loss: 3.851068 Train err: 52.6%\n",
      "[4-11 @ 21.7 sec] Loss: inf Train err: 100.0%\n",
      "[4-12 @ 21.8 sec] Loss: 3.072478 Train err: 100.0%\n",
      "[4-13 @ 21.8 sec] Loss: 3.572269 Train err: 57.7%\n",
      "[4-14 @ 21.9 sec] Loss: 3.450802 Train err: 52.9%\n",
      "[4-15 @ 21.9 sec] Loss: 3.637224 Train err: 43.9%\n",
      "[4-16 @ 22.0 sec] Loss: 3.559657 Train err: 56.0%\n",
      "[4-17 @ 22.1 sec] Loss: inf Train err: 100.0%\n",
      "[4-18 @ 22.2 sec] Loss: 3.780910 Train err: 39.1%\n",
      "[4-19 @ 22.2 sec] Loss: 3.569414 Train err: 57.2%\n",
      "[4-20 @ 22.4 sec] Loss: inf Train err: 100.0%\n",
      "Epoch [4] validation error: 89.909%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 4.00 GiB total capacity; 2.79 GiB already allocated; 62.61 MiB free; 2.85 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c7bbaa8299b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdecoder_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mencoder_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     epochs = epochs)\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\py\\dwg-crawl\\JupyterNotebooks\\train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(encoder, decoder, train_loader, val_loader, loss, decoder_opt, encoder_opt, epochs)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mencoder_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mouts_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearned_hidden_representation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mdecoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearned_hidden_representation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\py\\dwg-crawl\\JupyterNotebooks\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mentities_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\py\\dwg-crawl\\JupyterNotebooks\\model.py\u001b[0m in \u001b[0;36minit_hidden\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearned_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 4.00 GiB total capacity; 2.79 GiB already allocated; 62.61 MiB free; 2.85 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "lr = 11\n",
    "epochs = 30\n",
    "decoder_optimizer = torch.optim.Adam(rnn_decoder.parameters(), lr = lr)\n",
    "encoder_optimizer = torch.optim.Adam(rnn_encoder.parameters(), lr = lr)\n",
    "from chamfer_distance_loss import MyChamferDistance\n",
    "loss = MyChamferDistance()\n",
    "\n",
    "loss_history, train_history, val_history = train_model(\n",
    "    encoder = rnn_encoder, \n",
    "    decoder = rnn_decoder, \n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    loss = loss,\n",
    "    decoder_opt = decoder_optimizer,\n",
    "    encoder_opt = encoder_optimizer,\n",
    "    epochs = epochs)\n",
    "\n",
    "plot_history(loss_history, train_history, val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 86% |\n"
     ]
    }
   ],
   "source": [
    "# https://blog.paperspace.com/pytorch-memory-multi-gpu-debugging/\n",
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import calculate_accuracy\n",
    "i = 0\n",
    "for (x, y) in iter(val_loader):\n",
    "    outs, learned = rnn_encoder(x)\n",
    "    decoded = rnn_decoder(outs, learned)\n",
    "    \n",
    "    yyy = []\n",
    "    for yy in y:\n",
    "        yyy.append(yy.shape[0])\n",
    "    ppp = []\n",
    "    for dd in decoded:\n",
    "        ppp.append(dd.shape[0])\n",
    "    \n",
    "    print('actual:', yyy)\n",
    "    print('predicted:', ppp)\n",
    "    \n",
    "    lv = loss(decoded, y)\n",
    "    print ('loss:', lv)\n",
    "\n",
    "    acc = calculate_accuracy(decoded, y)\n",
    "    print('accuracy:', acc)\n",
    "\n",
    "    i += 1\n",
    "    print(i, '------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = pd.DataFrame(x[0].cpu().detach().numpy())\n",
    "print(ii.head())\n",
    "yy = pd.DataFrame(y[0].cpu().detach().numpy())\n",
    "print(len(yy))\n",
    "print(yy.head())\n",
    "pp = pd.DataFrame(decoded[0].cpu().detach().numpy())\n",
    "print(len(pp))\n",
    "print(pp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import calculate_accuracy\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "rnn_encoder.eval()\n",
    "rnn_decoder.eval()\n",
    "\n",
    "test_accuracies = []\n",
    "for (x,y) in test_loader:\n",
    "    with torch.no_grad():\n",
    "        out, hidden = rnn_encoder(x)\n",
    "        prediction = rnn_decoder(out, hidden)\n",
    "        accuracy = calculate_accuracy(prediction, y)\n",
    "        test_accuracies.append(accuracy)\n",
    "        \n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print('Accuracy on testing: {0:2.3f}'.format(mean_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
